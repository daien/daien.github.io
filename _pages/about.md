---
permalink: /
title: "Adrien Gaidon, PhD"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

Dr. Adrien Gaidon is an experienced Machine Learning researcher, engineer, manager, executive, advisor, and investor. He is a Partner at [Calibrate Ventures](https://www.calibratevc.com/), an Adjunct Professor of Computer Science at Stanford, and a technical advisor and former head of ML at [TRI](https://www.tri.global/).

Since 2007, Dr. Gaidon has been working on Principle-centric ML: learning algorithms that effectively combine concise prior knowledge and large-scale data. In particular, Dr. Gaidon has a deep expertise in Embodied Intelligence, including Computer Vision, Autonomous Driving, and Robotics, with more than 100 patents and 100 publications at top AI venues like CVPR and NeurIPS.

Besides scientific expertise, Dr. Gaidon has experience in building and leading world-class teams of ML researchers and engineers that work together to invent and develop new solutions to hard real-world problems like safe and automated driving.

More info: [CV](/files/CV_Adrien_Gaidon.pdf), [linkedin](https://www.linkedin.com/in/adrien-gaidon-63ab2358/), [Google Scholar](https://scholar.google.com/citations?user=2StUgf4AAAAJ&hl=en), [DBLP](https://dblp.org/pid/06/7548.html), [arxiv](https://arxiv.org/search/cs?searchtype=author&query=Gaidon%2C+A).


## News

- End of 2024: early-stage investments in some amazing deep tech startups that we made at [Calibrate Ventures](https://www.calibratevc.com/) (more news soon!).
- December 2024: presenting [Streaming Detection of Queried Event Start](https://neurips.cc/virtual/2024/poster/97778) at **NeurIPS'24** with Cristobal Eyzaguirre and Stanford colleagues.
- October 2024: presenting [Linearizing Large Language Models
](https://arxiv.org/abs/2405.06640) at **CoLM'24** (a little bit of the whole lot of LLM work that happened behind the scenes at TRI!)
- September 2024: two papers leveraging MAE (Masked Auto-Encoders) for 3D vision presented at **ECCV'24**: [NeRF-MAE](https://nerf-mae.github.io/) and [OctMAE](https://sh8.io/#/oct_mae).
- July 2024: if you want to learn about the intersection of CV for robotics and VC, I gave an unusual talk at the excellent [ICRA'24 RoboNeRF workshop](https://robonerf.github.io/2024/) titled "[Robot Ventures in Neural Fields](https://youtu.be/jyEZtbXs3fg?si=w8atWZqDl_W__hyD&t=12647)".
- June 2024: [VTCD: Understanding Video Transformers via Universal Concept Discovery](https://yorkucvil.github.io/VTCD/) presented at **CVPR'24** (as a highlight!).
- June 2024: [ReFiNe: Recursive Field Networks for Cross-Modal Multi-Scene Representation](https://zakharos.github.io/projects/refine/) presented at **SIGGRAPH'24**.
- February 2024: **Big personal news**: after 7 wonderful years leading ML at TRI, I'm thrilled to be joining the early-stage deep tech VC firm **[Calibrate Ventures](https://www.calibratevc.com/)** as a Partner to invest in the explosion of Embodied Intelligence startups! If you are curious about why and how, then check out my [personal blog post](https://adriengaidon.com/posts/2024/02/calibrate/) and the [Calibrate announcement](https://www.calibratevc.com/blog/calibrate-ventures-welcomes-adrien-gaidon-as-partner).

### 2023 Updates

- July 2023: [Robust Self-Supervised Extrinsic Self-Calibration](https://sites.google.com/view/tri-sesc) accepted at **IROS'23**, and 3 papers accepted at [**ICCV'23**](https://iccv2023.thecvf.com/): [ZeroDepth](https://sites.google.com/view/tri-zerodepth) (scale-aware monocular depth that generalizes zero-shot across domains, including indoors and outdoors!), [DeLiRa](https://sites.google.com/view/tri-delira) (self-supervised depth, light, and radiance fields), and [NeO 360](https://zubair-irshad.github.io/projects/neo360.html) (outdoor NeRFs from sparse views).
- June 2023: we received the **best paper award at [L4DC'23](https://l4dc.seas.upenn.edu/)** for [iDBF: Self-Supervised Policy Filters that Avoid Out-of-Distribution States](https://arxiv.org/abs/2301.12012)! Congrats Fernando and Haruki!
- May 2023: 3 papers published at **CVPR'23**: [a new 3D detector using view-point equivariance (VEDet)](https://arxiv.org/abs/2303.14548), [a new video object segmentation benchmark (VOST)](https://arxiv.org/abs/2212.06200), [a new video model for object discovery from motion-guided tokens (MoTok)](https://arxiv.org/abs/2303.15555), and more from the team as mentioned in our [TRI @ CVPR 2023 blog](https://medium.com/toyotaresearch/tri-at-cvpr-2023-666c78cb4330).
- January 2023: [Neural Groundplans](https://prafullsharma.net/see3d/) published at **ICLR'23**, [Depth Is All You Need for 3D Detection](https://arxiv.org/abs/2210.02493) at **ICRA'23**, and [Active Sampling to reduce Causal Confusion](https://proceedings.mlr.press/v213/gupta23a.html) at [CLEAR'23](https://www.cclear.cc/2023) and the NeurIPS'23 [CML4Impact workshop](https://www.cml-4-impact.vanderschaar-lab.com/).

### 2022 Updates

- September 2022: 3 papers accepted at **CoRL'22**: [ROAD: Learning an Implicit Recursive Octree Auto-Decoder to Efficiently Encode 3D Shapes](https://openreview.net/forum?id=EVFrjBgYsPZ), [Representation Learning for Object Detection from Unlabeled Point Cloud Sequences](https://openreview.net/forum?id=nuAGobCwb8V), and [RAP: Risk-Aware Prediction for Robust Planning](https://openreview.net/forum?id=z_hPo2Fu9A3) (**oral**).
- July 2022: 4 papers accepted at **ECCV'22**: [Depth Field Networks (DeFiNe)](https://arxiv.org/abs/2207.14287), [implicit representations of shape and appearance (ShAPO)](https://arxiv.org/abs/2207.13691), [Photo-realistic Neural Domain Randomization (PNDR)](https://arxiv.org/abs/2210.12682), [Stochastic Sequential Pointcloud Forecasting (S2Net)](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870541.pdf).
- June 2022: I am proposing a new paradigm for Embodied Intelligence: **Principle-centric AI**. See an intro in my [TWiMLAI podcast with Sam Charrington](https://twimlai.com/podcast/twimlai/principle-centric-ai-adrien-gaidon/) and a [technical presentation at ICRA'22](https://www.youtube.com/watch?v=qzo61V7G1EM&t=8312s).
- June 2022: one paper accepted at **IROS'22** on [uncertainty modeling for trajectory forecasting (HAICU)](https://arxiv.org/abs/2104.12446)
- May 2022: new paper accepted at **ICML'22**: [Object Permanence Emerges in a Random Walk along Memory](https://arxiv.org/abs/2204.01784).
- March 2022: 3 papers accepted at **CVPR'22**:  [Revisiting the "Video" in Video-Language Understanding](https://arxiv.org/abs/2206.01720) (**oral**), [Multi-Frame Self-Supervised Depth with Transformers](https://arxiv.org/abs/2204.07616), [Discovering Objects that Can Move](https://arxiv.org/abs/2203.10159).
- February 2022: 4 papers accepted at **ICRA'22**: [Full Surround Monodepth from Multiple Cameras](https://arxiv.org/abs/2104.00152) (FSM), [Self-Supervised Camera Self-Calibration from Video](https://arxiv.org/abs/2112.03325), [Learning Optical Flow, Depth, and Scene Flow without Real-World Labels](https://arxiv.org/abs/2203.15089), and [Control-Aware  Prediction  Objectives  for  Autonomous  Driving](https://arxiv.org/abs/2204.13319).
- January 2022: 2 papers accepted as **spotlights at ICLR'22**: [Self-supervised Learning is More Robust to Dataset Imbalance](https://arxiv.org/abs/2110.05025) and [Dynamics-Aware Comparison of Learned Reward Functions (DARD)](https://arxiv.org/abs/2201.10081).

### 2021 Updates

- Fall 2021: co-teaching [CS131: Computer Vision: Foundations and Applications](http://vision.stanford.edu/teaching/cs131_fall2122/index.html) at Stanford with Juan Carlos Niebles.
- October 2021: presenting our papers at **[ICCV'21](https://www.tri.global/news/tri-iccv-2021/)**, including work on Self-supervised sim-to-real transfer ([GUDA](https://arxiv.org/abs/2103.16694)), Learning to Track with Object Permanence ([PermaTrack](https://arxiv.org/abs/2103.14258)), self-supervised pre-training for monocular 3D object detection ([DD3D](https://arxiv.org/abs/2108.06417)), and video auto-labeling ([Warp-Refine Propagation](https://arxiv.org/abs/2109.13432)). I also gave 3 workshop talks on 3D detection at [3DODI](https://sites.google.com/unitn.it/3dodi), scene understanding at [ROAD](https://sites.google.com/view/roadchallangeiccv2021/), and trajectory forecasting at [BTFM](https://sites.google.com/view/btfm2021/). See our [medium post](https://medium.com/toyotaresearch/tri-at-iccv-2021-1d807ad4740a) for an overview.
- September 2021: one **oral at [NeurIPS'21](https://nips.cc/) (top 1% of ~10k submissions!)** on [Provable Guarantees for Self-Supervised Learning](https://arxiv.org/abs/2106.04156) and one paper accepted at **[CoRL'21](https://www.robot-learning.org/)** on [Single Shot Scene Reconstruction](https://openreview.net/forum?id=CGn3XKSf7vf).
- August 2021: my team is growing! We are hiring **4 new Research Scientists** in areas including [Perception](https://jobs.lever.co/tri/30b2e353-ca5a-43fc-bdce-08369b6f3bc9), [Reconstruction / Inverse Graphics](https://jobs.lever.co/tri/4ead5bb5-c0b7-4fd8-9603-e63970a7cc77), [Computer Vision Safety](https://jobs.lever.co/tri/fbb46694-f7b9-4582-bbdb-2d650d638ef9), and [RL Safety](https://jobs.lever.co/tri/3072275b-dcd7-4406-963f-0e84f2a61089). Please apply if you are interested in joining a talented team on a mission to discover the learning principles for safe robot autonomy and human amplification at scale!
- July 2021: I gave a talk on [Bridging the Perception-Control gap with Prediction](https://www.youtube.com/watch?v=EmrReoNQP3s&t=4840s) at [RSS'21](https://negarmehr.github.io/RSS2021Workshop/).
- July 2021: I did a [fun interview](https://paralleldomain.com/how-tri-trains-better-computer-vision-models-with-pd-synthetic-data/) with the founder & CEO of [Parallel Domain](https://paralleldomain.com/), Kevin McNamara, on how we use Synthetic Data to advance the state of the art in Computer Vision. PD also made a cool blog covering our recent [PermaTrack](https://arxiv.org/abs/2103.14258) work.
- June 2021: we are organizing the **[CVPR'21 DDAD depth estimation challenge](https://eval.ai/web/challenges/challenge-page/902/overview)**! Try your ideas on public data from our TRI fleet! Winners will win prizes and present, along with prestigious invited speakers, at our **[Mono3D CVPR'21 workshop](https://sites.google.com/view/mono3d-workshop/)** on the Frontiers of Monocular 3D Perception.
- May 2021: got an **[outstanding reviewer award at CVPR](http://cvpr2021.thecvf.com/node/184)**!
- May 2021: together with Vitor and Rares, we wrote a blog post summarizing a lot of our research results in [self-supervised learning for depth estimation](https://medium.com/toyotaresearch/self-supervised-learning-in-depth-part-1-of-2-74825baaaa04).
- May 2021: I did a [fun interview about ML for Autonomous Driving](https://wandb.ai/wandb_fc/gradient-dissent/reports/TRI-s-Adrien-Gaidon-on-advancing-ML-research-in-autonomous-vehicles--Vmlldzo2MzEzMTE) with Lukas Biewald for the Gradient Dissent podcast. Check it out!
- April 2021: new preprints on Full Surround Monodepth ([FSM](https://arxiv.org/abs/2104.00152)) and trajectory forecasting ([HAICU](https://arxiv.org/abs/2104.12446)).
- March 2021: **2 multi-task learning papers accepted at [CVPR'21](http://cvpr2021.thecvf.com/)**, one on joint depth prediction and completion ([PackNet-SAN](/publication/2021-06-19-Sparse-Auxiliary-Networks-for-Unified-Monocular-Depth-Prediction-and-Completion)) and another on [Hierarchical Lov√°sz Embeddings for panoptic segmentation](/publication/2021-06-19-Hierarchical-Lovasz-Embeddings-for-Proposal-free-Panoptic-Segmentation).
- March 2021: Blake Wulfe and I **won the [NeurIPS 2020 ProcGen RL Competition](https://www.aicrowd.com/challenges/neurips-2020-procgen-competition)**! Find the full report [here](https://arxiv.org/abs/2103.15332).
- February 2021: 1 paper at RoboSoft in collaboration with the brilliant TRI Robotics team on [monocular depth estimation inside visuotactile sensors](/publication/2021-01-22-Monocular-Depth-SoftBubble).
- January 2021: 1 paper on [distributionally robust control](/publication/2021-01-30-RAT-iLQR) accepted at **RA-L/ICRA** and another at **[ICLR](https://iclr.cc/)** on [regularization for heteroskedastic and imbalanced Deep Learning](/publication/2021-01-12-Heteroskedastic-and-Imbalanced-Deep-Learning). Both on robustness and with great Stanford collaborators from [Mac Schwager](https://web.stanford.edu/~schwager/) and [Tengyu Ma](https://ai.stanford.edu/~tengyuma/)'s labs.

### 2020 Updates

- November 2020: 1 paper (**oral**) at [3DV](http://3dv2020.dgcv.nii.ac.jp/) on [Neural Ray Surfaces](/publication/2020-08-15-Neural-Ray-Surfaces) in collaboration with [Greg Shakhnarovich](https://ttic.uchicago.edu/~gregory/) at TTIC.
- October 2020: got a "top 10% reviewer award" at NeurIPS!
- October 2020: 2 papers accepted at [CoRL 2020](https://www.robot-learning.org/), including one **[oral on self-supervised 3D keypoints](/publication/2020-11-16-KP3D-Self-supervised-3D-Kepyoints)** and a [poster on interpretable trajectory forecasting](/publication/2020-11-16-MATS-Trajectory-Forecasting) in collaboration with [Marco Pavone](https://web.stanford.edu/~pavone/)'s lab at Stanford
- October 2020: I gave an [invited talk at IPAM](https://www.youtube.com/watch?v=HltMaglvFKg) covering a lot of our recent results across the full AV stack.
- August 2020: we are organizing the [ECCV 2020 workshop on Perception for Autonomous Driving (PAD)](https://sites.google.com/view/pad2020)
- July 2020: we are organizing the [ICML 2020 workshop on AI for Autonomous Driving (AIAD)](https://sites.google.com/view/aiad2020)
- July 2020: 2 papers accepted at [ECCV 2020](https://eccv2020.eu/), including an **[oral on trajectory prediction](/publication/2020-08-23-Endpoint-Conditioned-Trajectory-Prediction)** and a [poster on differentiable rendering](/publication/2020-08-23-Self-Supervised-Differentiable-Rendering)
- July 2020: [5 papers](/publications/) accepted at [IROS 2020](https://www.iros2020.org/) and 1 at [ITSC](https://www.ieee-itsc2020.org/) on [scene flow](/publication/2020-10-25-End-to-end-Birds-eye-view-Flow), [imitation learning](/publication/2020-10-25-Driving-Through-Ghosts), [game-theoretic planning](/publication/2020-10-25-Game-Theoretic-Planning-Risk-Aware), [risk sensitive control](/publication/2020-10-25-Risk-Sensitive-Control-Trajectron), [traffic simulation](/publication/2020-10-25-Behaviorally-Diverse-Traffic-Simulation-via-RL), and [planner testing](/publication/2020-09-20-Discovering-Avoidable-Planner-Failures).
- July 2020: [1 paper with Stanford on hierarchical RL and imitation in near-accidents](/publication/2020-07-15-Reinforcement-Learning-based-Control-of-Imitative-Policies-for-Near-Accident-Driving) accepted at [RSS 2020](https://roboticsconference.org/)
- June 2020: Together with colleagues from PFN and TRI-AD, we have released a [survey on Differentiable Rendering](/publication/2020-06-22-Differentiable-Rendering-Survey).
- June 2020: 4 papers (**3 orals!**) accepted at [CVPR 2020](http://cvpr2020.thecvf.com/) ([PackNet pseudo-lidar](/publication/2020-06-16-3D-Packing-for-Self-Supervised-Monocular-Depth-Estimation), [real-time panoptic segmentation](/publication/2020-06-16-Real-Time-Panoptic-Segmentation-from-Dense-Detections), [auto-labeling via Differentiable Rendering](/publication/2020-06-16-Autolabeling-3D-Objects-with-Differentiable-Rendering), [spatio-temporal graph distillation](/publication/2020-06-16-Spatio-Temporal-Graph-for-Video-Captioning)). See also our new [DDAD dataset](https://github.com/TRI-ML/DDAD) for depth estimation!
- February 2020: [1 paper with Stanford on Pedestrian Intent Prediction](/publication/2020-05-31-Spatiotemporal-Relationship-Reasoning-for-Pedestrian-Intent-Prediction) accepted at [RA-L](https://www.ieee-ras.org/publications/ra-l)/[ICRA 2020](https://www.icra2020.org/). See also our new [STIP dataset](https://stip.stanford.edu/dataset.html)!
- January 2020: I got promoted to Senior Manager! Super grateful to my team and excited for our next steps together!

### 2019 updates

- December 2019: 1 paper accepted at [ICLR 2020](https://iclr.cc/virtual/poster_ByxT7TNFvH.html) and 1 (**oral**) at [WACV 2020](http://wacv20.wacv.net/)
- October 2019: 1 paper accepted at the [International Journal of Computer Vision (IJCV)](https://link.springer.com/article/10.1007/s11263-019-01222-z)
- September 2019: 1 paper accepted at [NeurIPS 2019](https://nips.cc/Conferences/2019/Schedule?showEvent=13370) (also oral at [BayLearn 2019](https://www.youtube.com/watch?v=EIF6Sy3ZKYQ&feature=emb_logo)) and 2 papers (**spotlights**) accepted at [CoRL 2019](https://sites.google.com/robot-learning.org/corl2019)
- July 2019: 1 paper accepted (**oral**) at [ICCV 2019](https://conftube.com/video/2ntDYowHbZs?tocitem=134)
- May 2019: I did an interview with the wonderful Sam Charrington for the [TWIML AI podcast](https://twimlai.com/twiml-talk-269-advancing-autonomous-vehicle-development-using-distributed-deep-learning-with-adrien-gaidon/)!
- Finally started a personal website!
