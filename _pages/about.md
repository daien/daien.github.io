---
permalink: /
title: "Adrien Gaidon, PhD"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am the head of Machine Learning at the [Toyota Research Institute (TRI)](https://www.tri.global/) and an Adjunct Professor at Stanford, CA, USA. My work focuses on Principle-centric ML (combining knowledge and data) for Embodied Intelligence (physical ML systems), spanning Scene and Behavior Understanding, Simulation for Deep Learning, 3D Computer Vision, and Self-Supervised Learning (cf. [a short bio](#bio) and my [CV](/cv) for more info). Outside of work, I spend time with my wife, daughter, and the mountains (I love camping, climbing, and snowboarding).

## News

- June 2023: we received the **best paper award at [L4DC'23](https://l4dc.seas.upenn.edu/)** for [iDBF: Self-Supervised Policy Filters that Avoid Out-of-Distribution States](https://arxiv.org/abs/2301.12012)! Congrats Fernando and Haruki!
- May 2023: 3 papers published at **CVPR'23**: [a new 3D detector using view-point equivariance (VEDet)](https://arxiv.org/abs/2303.14548), [a new video object segmentation benchmark (VOST)](https://arxiv.org/abs/2212.06200), [a new video model for object discovery from motion-guided tokens (MoTok)](https://arxiv.org/abs/2303.15555), and more from the team as mentioned in our [TRI @ CVPR 2023 blog](https://medium.com/toyotaresearch/tri-at-cvpr-2023-666c78cb4330).
- January 2023: [Neural Groundplans](https://prafullsharma.net/see3d/) published at **ICLR'23**, [Depth Is All You Need for 3D Detection](https://arxiv.org/abs/2210.02493) at **ICRA'23**, and [Active Sampling to reduce Causal Confusion](https://openreview.net/forum?id=IaaRcteVzuc) at the NeurIPS'23 [CML4Impact workshop](https://www.cml-4-impact.vanderschaar-lab.com/).
- September 2022: 3 papers accepted at **CoRL'22**: [ROAD: Learning an Implicit Recursive Octree Auto-Decoder to Efficiently Encode 3D Shapes](https://openreview.net/forum?id=EVFrjBgYsPZ), [Representation Learning for Object Detection from Unlabeled Point Cloud Sequences](https://openreview.net/forum?id=nuAGobCwb8V), and [RAP: Risk-Aware Prediction for Robust Planning](https://openreview.net/forum?id=z_hPo2Fu9A3) (**oral**).
- July 2022: 4 papers accepted at **ECCV'22**: [Depth Field Networks (DeFiNe)](https://arxiv.org/abs/2207.14287), [implicit representations of shape and appearance (ShAPO)](https://arxiv.org/abs/2207.13691), [Photo-realistic Neural Domain Randomization (PNDR)](https://arxiv.org/abs/2210.12682), [Stochastic Sequential Pointcloud Forecasting (S2Net)](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870541.pdf).
- June 2022: I am proposing a new paradigm for Embodied Intelligence: **Principle-centric AI**. See an intro in my [TWiMLAI podcast with Sam Charrington](https://twimlai.com/podcast/twimlai/principle-centric-ai-adrien-gaidon/) and a [technical presentation at ICRA'22](https://www.youtube.com/watch?v=qzo61V7G1EM&t=8312s).
- June 2022: one paper accepted at **IROS'22** on [uncertainty modeling for trajectory forecasting (HAICU)](https://arxiv.org/abs/2104.12446)
- May 2022: new paper accepted at **ICML'22**: [Object Permanence Emerges in a Random Walk along Memory](https://arxiv.org/abs/2204.01784).
- March 2022: 3 papers accepted at **CVPR'22**:  [Revisiting the "Video" in Video-Language Understanding](https://arxiv.org/abs/2206.01720) (**oral**), [Multi-Frame Self-Supervised Depth with Transformers](https://arxiv.org/abs/2204.07616), [Discovering Objects that Can Move](https://arxiv.org/abs/2203.10159).
- February 2022: 4 papers accepted at **ICRA'22**: [Full Surround Monodepth from Multiple Cameras](https://arxiv.org/abs/2104.00152) (FSM), [Self-Supervised Camera Self-Calibration from Video](https://arxiv.org/abs/2112.03325), [Learning Optical Flow, Depth, and Scene Flow without Real-World Labels](https://arxiv.org/abs/2203.15089), and [Control-Aware  Prediction  Objectives  for  Autonomous  Driving](https://arxiv.org/abs/2204.13319).
- January 2022: 2 papers accepted as **spotlights at ICLR'22**: [Self-supervised Learning is More Robust to Dataset Imbalance](https://arxiv.org/abs/2110.05025) and [Dynamics-Aware Comparison of Learned Reward Functions (DARD)](https://arxiv.org/abs/2201.10081).

### 2021 Updates

- Fall 2021: co-teaching [CS131: Computer Vision: Foundations and Applications](http://vision.stanford.edu/teaching/cs131_fall2122/index.html) at Stanford with Juan Carlos Niebles.
- October 2021: presenting our papers at **[ICCV'21](https://www.tri.global/news/tri-iccv-2021/)**, including work on Self-supervised sim-to-real transfer ([GUDA](https://arxiv.org/abs/2103.16694)), Learning to Track with Object Permanence ([PermaTrack](https://arxiv.org/abs/2103.14258)), self-supervised pre-training for monocular 3D object detection ([DD3D](https://arxiv.org/abs/2108.06417)), and video auto-labeling ([Warp-Refine Propagation](https://arxiv.org/abs/2109.13432)). I also gave 3 workshop talks on 3D detection at [3DODI](https://sites.google.com/unitn.it/3dodi), scene understanding at [ROAD](https://sites.google.com/view/roadchallangeiccv2021/), and trajectory forecasting at [BTFM](https://sites.google.com/view/btfm2021/). See our [medium post](https://medium.com/toyotaresearch/tri-at-iccv-2021-1d807ad4740a) for an overview.
- September 2021: one **oral at [NeurIPS'21](https://nips.cc/) (top 1% of ~10k submissions!)** on [Provable Guarantees for Self-Supervised Learning](https://arxiv.org/abs/2106.04156) and one paper accepted at **[CoRL'21](https://www.robot-learning.org/)** on [Single Shot Scene Reconstruction](https://openreview.net/forum?id=CGn3XKSf7vf).
- August 2021: my team is growing! We are hiring **4 new Research Scientists** in areas including [Perception](https://jobs.lever.co/tri/30b2e353-ca5a-43fc-bdce-08369b6f3bc9), [Reconstruction / Inverse Graphics](https://jobs.lever.co/tri/4ead5bb5-c0b7-4fd8-9603-e63970a7cc77), [Computer Vision Safety](https://jobs.lever.co/tri/fbb46694-f7b9-4582-bbdb-2d650d638ef9), and [RL Safety](https://jobs.lever.co/tri/3072275b-dcd7-4406-963f-0e84f2a61089). Please apply if you are interested in joining a talented team on a mission to discover the learning principles for safe robot autonomy and human amplification at scale!
- July 2021: I gave a talk on [Bridging the Perception-Control gap with Prediction](https://www.youtube.com/watch?v=EmrReoNQP3s&t=4840s) at [RSS'21](https://negarmehr.github.io/RSS2021Workshop/).
- July 2021: I did a [fun interview](https://paralleldomain.com/how-tri-trains-better-computer-vision-models-with-pd-synthetic-data/) with the founder & CEO of [Parallel Domain](https://paralleldomain.com/), Kevin McNamara, on how we use Synthetic Data to advance the state of the art in Computer Vision. PD also made a cool blog covering our recent [PermaTrack](https://arxiv.org/abs/2103.14258) work.
- June 2021: we are organizing the **[CVPR'21 DDAD depth estimation challenge](https://eval.ai/web/challenges/challenge-page/902/overview)**! Try your ideas on public data from our TRI fleet! Winners will win prizes and present, along with prestigious invited speakers, at our **[Mono3D CVPR'21 workshop](https://sites.google.com/view/mono3d-workshop/)** on the Frontiers of Monocular 3D Perception.
- May 2021: got an **[outstanding reviewer award at CVPR](http://cvpr2021.thecvf.com/node/184)**!
- May 2021: together with Vitor and Rares, we wrote a blog post summarizing a lot of our research results in [self-supervised learning for depth estimation](https://medium.com/toyotaresearch/self-supervised-learning-in-depth-part-1-of-2-74825baaaa04).
- May 2021: I did a [fun interview about ML for Autonomous Driving](https://wandb.ai/wandb_fc/gradient-dissent/reports/TRI-s-Adrien-Gaidon-on-advancing-ML-research-in-autonomous-vehicles--Vmlldzo2MzEzMTE) with Lukas Biewald for the Gradient Dissent podcast. Check it out!
- April 2021: new preprints on Full Surround Monodepth ([FSM](https://arxiv.org/abs/2104.00152)) and trajectory forecasting ([HAICU](https://arxiv.org/abs/2104.12446)).
- March 2021: **2 multi-task learning papers accepted at [CVPR'21](http://cvpr2021.thecvf.com/)**, one on joint depth prediction and completion ([PackNet-SAN](/publication/2021-06-19-Sparse-Auxiliary-Networks-for-Unified-Monocular-Depth-Prediction-and-Completion)) and another on [Hierarchical Lov√°sz Embeddings for panoptic segmentation](/publication/2021-06-19-Hierarchical-Lovasz-Embeddings-for-Proposal-free-Panoptic-Segmentation).
- March 2021: Blake Wulfe and I **won the [NeurIPS 2020 ProcGen RL Competition](https://www.aicrowd.com/challenges/neurips-2020-procgen-competition)**! Find the full report [here](https://arxiv.org/abs/2103.15332).
- February 2021: 1 paper at RoboSoft in collaboration with the brilliant TRI Robotics team on [monocular depth estimation inside visuotactile sensors](/publication/2021-01-22-Monocular-Depth-SoftBubble).
- January 2021: 1 paper on [distributionally robust control](/publication/2021-01-30-RAT-iLQR) accepted at **RA-L/ICRA** and another at **[ICLR](https://iclr.cc/)** on [regularization for heteroskedastic and imbalanced Deep Learning](/publication/2021-01-12-Heteroskedastic-and-Imbalanced-Deep-Learning). Both on robustness and with great Stanford collaborators from [Mac Schwager](https://web.stanford.edu/~schwager/) and [Tengyu Ma](https://ai.stanford.edu/~tengyuma/)'s labs.

### 2020 Updates

- November 2020: 1 paper (**oral**) at [3DV](http://3dv2020.dgcv.nii.ac.jp/) on [Neural Ray Surfaces](/publication/2020-08-15-Neural-Ray-Surfaces) in collaboration with [Greg Shakhnarovich](https://ttic.uchicago.edu/~gregory/) at TTIC.
- October 2020: got a "top 10% reviewer award" at NeurIPS!
- October 2020: 2 papers accepted at [CoRL 2020](https://www.robot-learning.org/), including one **[oral on self-supervised 3D keypoints](/publication/2020-11-16-KP3D-Self-supervised-3D-Kepyoints)** and a [poster on interpretable trajectory forecasting](/publication/2020-11-16-MATS-Trajectory-Forecasting) in collaboration with [Marco Pavone](https://web.stanford.edu/~pavone/)'s lab at Stanford
- October 2020: I gave an [invited talk at IPAM](https://www.youtube.com/watch?v=HltMaglvFKg) covering a lot of our recent results across the full AV stack.
- August 2020: we are organizing the [ECCV 2020 workshop on Perception for Autonomous Driving (PAD)](https://sites.google.com/view/pad2020)
- July 2020: we are organizing the [ICML 2020 workshop on AI for Autonomous Driving (AIAD)](https://sites.google.com/view/aiad2020)
- July 2020: 2 papers accepted at [ECCV 2020](https://eccv2020.eu/), including an **[oral on trajectory prediction](/publication/2020-08-23-Endpoint-Conditioned-Trajectory-Prediction)** and a [poster on differentiable rendering](/publication/2020-08-23-Self-Supervised-Differentiable-Rendering)
- July 2020: [5 papers](/publications/) accepted at [IROS 2020](https://www.iros2020.org/) and 1 at [ITSC](https://www.ieee-itsc2020.org/) on [scene flow](/publication/2020-10-25-End-to-end-Birds-eye-view-Flow), [imitation learning](/publication/2020-10-25-Driving-Through-Ghosts), [game-theoretic planning](/publication/2020-10-25-Game-Theoretic-Planning-Risk-Aware), [risk sensitive control](/publication/2020-10-25-Risk-Sensitive-Control-Trajectron), [traffic simulation](/publication/2020-10-25-Behaviorally-Diverse-Traffic-Simulation-via-RL), and [planner testing](/publication/2020-09-20-Discovering-Avoidable-Planner-Failures).
- July 2020: [1 paper with Stanford on hierarchical RL and imitation in near-accidents](/publication/2020-07-15-Reinforcement-Learning-based-Control-of-Imitative-Policies-for-Near-Accident-Driving) accepted at [RSS 2020](https://roboticsconference.org/)
- June 2020: Together with colleagues from PFN and TRI-AD, we have released a [survey on Differentiable Rendering](/publication/2020-06-22-Differentiable-Rendering-Survey).
- June 2020: 4 papers (**3 orals!**) accepted at [CVPR 2020](http://cvpr2020.thecvf.com/) ([PackNet pseudo-lidar](/publication/2020-06-16-3D-Packing-for-Self-Supervised-Monocular-Depth-Estimation), [real-time panoptic segmentation](/publication/2020-06-16-Real-Time-Panoptic-Segmentation-from-Dense-Detections), [auto-labeling via Differentiable Rendering](/publication/2020-06-16-Autolabeling-3D-Objects-with-Differentiable-Rendering), [spatio-temporal graph distillation](/publication/2020-06-16-Spatio-Temporal-Graph-for-Video-Captioning)). See also our new [DDAD dataset](https://github.com/TRI-ML/DDAD) for depth estimation!
- February 2020: [1 paper with Stanford on Pedestrian Intent Prediction](/publication/2020-05-31-Spatiotemporal-Relationship-Reasoning-for-Pedestrian-Intent-Prediction) accepted at [RA-L](https://www.ieee-ras.org/publications/ra-l)/[ICRA 2020](https://www.icra2020.org/). See also our new [STIP dataset](https://stip.stanford.edu/dataset.html)!
- January 2020: I got promoted to Senior Manager! Super grateful to my team and excited for our next steps together!

### Older updates

- December 2019: 1 paper accepted at [ICLR 2020](https://iclr.cc/virtual/poster_ByxT7TNFvH.html) and 1 (**oral**) at [WACV 2020](http://wacv20.wacv.net/)
- October 2019: 1 paper accepted at the [International Journal of Computer Vision (IJCV)](https://link.springer.com/article/10.1007/s11263-019-01222-z)
- September 2019: 1 paper accepted at [NeurIPS 2019](https://nips.cc/Conferences/2019/Schedule?showEvent=13370) (also oral at [BayLearn 2019](https://www.youtube.com/watch?v=EIF6Sy3ZKYQ&feature=emb_logo)) and 2 papers (**spotlights**) accepted at [CoRL 2019](https://sites.google.com/robot-learning.org/corl2019)
- July 2019: 1 paper accepted (**oral**) at [ICCV 2019](https://conftube.com/video/2ntDYowHbZs?tocitem=134)
- May 2019: I did an interview with the wonderful Sam Charrington for the [TWIML AI podcast](https://twimlai.com/twiml-talk-269-advancing-autonomous-vehicle-development-using-distributed-deep-learning-with-adrien-gaidon/)!


## Bio

Dr. Adrien Gaidon is the Director of Machine Learning at [Toyota Research Institute (TRI)](https://www.tri.global/) and an Adjunct Professor of computer science at Stanford University. Dr. Gaidon‚Äôs research focuses on discovering machine learning principles at the foundation of embodied intelligence. He has over 80 publications at top AI venues covering fundamental topics like Computer Vision and Learning for Robotics (cf. [Google Scholar](https://scholar.google.com/citations?user=2StUgf4AAAAJ&hl=en)). His research has led to more than 80 patents and applications in areas including safe and autonomous driving.
Dr. Gaidon received his Ph.D. from [Microsoft Research - Inria Paris](https://www.microsoft.com/en-us/research/collaboration/inria-joint-centre/) and has received multiple scientific awards at top conferences like CVPR and international AI competitions like PASCAL VOC and NeurIPS ProcGen.

You can find him at [adriengaidon.com](https://www.adriengaidon.com), on [linkedin](https://www.linkedin.com/in/adrien-gaidon-63ab2358/), and Twitter [@adnothing](https://twitter.com/adnothing).




